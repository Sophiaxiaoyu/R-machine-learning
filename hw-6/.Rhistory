geom_raster(mapping = aes(fill = log_post_2)) +
stat_contour(mapping = aes(z = log_post_2),
breaks = log(c(0.01/100, 0.01, 0.1, 0.5, 0.9)),
size = 2.2,
color = "black") +
# include the sample average (xbar) and the sample standard deviation (xsd)
geom_point(data = tibble::tibble(xbar =C1, xsd = C2),
mapping = aes(x = xbar, y = xsd),
shape = 22,
size = 4.5, fill = "orange", color = "steelblue") +
scale_fill_viridis_c(guide = FALSE, option = "viridis",
limits = log(c(0.01/100, 1.0))) +
labs(x = expression(mu), y = expression(sigma)) +
theme_bw()
my_cv_logpost <- function(unknowns, my_info)
{
# unpack the unknowns into separate variables
lik_mu <- unknowns[1]
lik_varphi <- unknowns[2]
# back transform to sigma
lik_sigma <- exp(lik_varphi)
# calculate the log-likelihood
log_lik <- sum(dnorm(x = my_info$xobs,
mean = lik_mu,
sd = lik_sigma,
log = TRUE))
# calculate the log-prior on mu
log_prior_mu <- dnorm(x = lik_mu,
mean = my_info$mu_0,
sd = my_info$tau_0,
log = TRUE)
# calculate the log-prior on sigma
log_prior_sigma <- dexp(x = lik_sigma,
rate = my_info$sigma_rate,
log = TRUE)
# calculate the log-derivative adjustment
log_deriv_adjust <-  lik_varphi
# return the (un-normalized) log-posterior
unnormalized_log_p<-log_lik + log_prior_mu + log_prior_sigma + log_deriv_adjust
unnormalized_log_p
}
my_cv_logpost(c(13, 0), hw06_info)
init_guess_01 <- c(10, 0.75)
init_guess_02 <- c(11.75, 1.85)
result1<-my_cv_logpost(c(13, 0), hw06_info)
result1
result2<-my_cv_logpost(c(7, -1), hw06_info)
result2
cv_param_grid <- expand.grid(mu =seq(mu_grid_lwr, mu_grid_upr, length.out = 251) ,
varphi =seq(varphi_grid_lwr, varphi_grid_upr, length.out = 251) ,
KEEP.OUT.ATTRS = FALSE, stringsAsFactors = FALSE) %>%
as.data.frame() %>% tibble::as_tibble()
varphi_grid_lwr <- log(sigma_grid_lwr)
varphi_grid_upr <- log(sigma_grid_upr)
cv_param_grid <- expand.grid(mu =seq(mu_grid_lwr, mu_grid_upr, length.out = 251) ,
varphi =seq(varphi_grid_lwr, varphi_grid_upr, length.out = 251) ,
KEEP.OUT.ATTRS = FALSE, stringsAsFactors = FALSE) %>%
as.data.frame() %>% tibble::as_tibble()
hw06_info
cv_param_grid %>%
mutate(log_post = log_post_cv_result,
log_post_2 = log_post - max(log_post)) %>%
ggplot(mapping = aes(x = mu, y = varphi)) +
geom_raster(mapping = aes(fill = log_post_2)) +
stat_contour(mapping = aes(z = log_post_2),
breaks = log(c(0.01/100, 0.01, 0.1, 0.5, 0.9)),
size = 2.2,
color = "black") +
# include the sample average (xbar) and the log-sample standard deviation (log_xsd)
geom_point(data = tibble::tibble(xbar =mean(hw06_info$xobs) ,
log_xsd =log(sd(hw06_info$xobs))),
mapping = aes(x = xbar, y = log_xsd),
shape = 22,
size = 4.5, fill = "orange", color = "steelblue") +
scale_fill_viridis_c(guide = FALSE, option = "viridis",
limits = log(c(0.01/100, 1.0))) +
labs(x = expression(mu), y = expression(varphi)) +
theme_bw()
log_post_cv_result <- purrr::map2_dbl(cv_param_grid$mu, cv_param_grid$varphi,
eval_logpost,
logpost_func = my_cv_logpost,
logpost_info = hw06_info)
cv_param_grid %>%
mutate(log_post = log_post_cv_result,
log_post_2 = log_post - max(log_post)) %>%
ggplot(mapping = aes(x = mu, y = varphi)) +
geom_raster(mapping = aes(fill = log_post_2)) +
stat_contour(mapping = aes(z = log_post_2),
breaks = log(c(0.01/100, 0.01, 0.1, 0.5, 0.9)),
size = 2.2,
color = "black") +
# include the sample average (xbar) and the log-sample standard deviation (log_xsd)
geom_point(data = tibble::tibble(xbar =mean(hw06_info$xobs) ,
log_xsd =log(sd(hw06_info$xobs))),
mapping = aes(x = xbar, y = log_xsd),
shape = 22,
size = 4.5, fill = "orange", color = "steelblue") +
scale_fill_viridis_c(guide = FALSE, option = "viridis",
limits = log(c(0.01/100, 1.0))) +
labs(x = expression(mu), y = expression(varphi)) +
theme_bw()
init_guess_01 <- c(10, 0.75)
init_guess_02 <- c(11.75, 1.85)
cv_param_grid %>%
mutate(log_post = log_post_cv_result,
log_post_2 = log_post - max(log_post)) %>%
ggplot(mapping = aes(x = mu, y = varphi)) +
geom_raster(mapping = aes(fill = log_post_2)) +
stat_contour(mapping = aes(z = log_post_2),
breaks = log(c(0.01/100, 0.01, 0.1, 0.5, 0.9)),
size = 2.2,
color = "black") +
# include the initial guess points
geom_point(data = tibble::tibble(attempt = as.character(1:2),
mu = c(init_guess_01[1], init_guess_02[1]),
varphi =c(init_guess_01[2], init_guess_02[2]) ),
mapping = aes(color = attempt),
size = 4.5) +
scale_fill_viridis_c(guide = FALSE, option = "viridis",
limits = log(c(0.01/100, 1.0))) +
labs(x = expression(mu), y = expression(varphi)) +
theme_bw()
cv_param_grid %>%
mutate(log_post = log_post_cv_result,
log_post_2 = log_post - max(log_post)) %>%
ggplot(mapping = aes(x = mu, y = varphi)) +
geom_raster(mapping = aes(fill = log_post_2)) +
stat_contour(mapping = aes(z = log_post_2),
breaks = log(c(0.01/100, 0.01, 0.1, 0.5, 0.9)),
size = 2.2,
color = "black") +
# include the initial guess points
geom_point(data = tibble::tibble(attempt = as.character(1:2),
mu = c(init_guess_01[1], init_guess_01[2]),
varphi =c(init_guess_02[1], init_guess_02[2]) ),
mapping = aes(color = attempt),
size = 4.5) +
scale_fill_viridis_c(guide = FALSE, option = "viridis",
limits = log(c(0.01/100, 1.0))) +
labs(x = expression(mu), y = expression(varphi)) +
theme_bw()
cv_param_grid %>%
mutate(log_post = log_post_cv_result,
log_post_2 = log_post - max(log_post)) %>%
ggplot(mapping = aes(x = mu, y = varphi)) +
geom_raster(mapping = aes(fill = log_post_2)) +
stat_contour(mapping = aes(z = log_post_2),
breaks = log(c(0.01/100, 0.01, 0.1, 0.5, 0.9)),
size = 2.2,
color = "black") +
# include the initial guess points
geom_point(data = tibble::tibble(attempt = as.character(1:2),
mu = c(init_guess_01[1], init_guess_02[1]),
varphi =c(init_guess_01[2], init_guess_02[2]) ),
mapping = aes(color = attempt),
size = 4.5) +
scale_fill_viridis_c(guide = FALSE, option = "viridis",
limits = log(c(0.01/100, 1.0))) +
labs(x = expression(mu), y = expression(varphi)) +
theme_bw()
map_res_01 <- optim(init_guess_01,
my_cv_logpost,
gr = NULL,
hw06_info,
method = "BFGS",
hessian = TRUE,
control = list(fnscale = -1, maxit = 1001))
map_res_02 <- optim(init_guess_02,
my_cv_logpost,
gr = NULL,
hw06_info,
method = "BFGS",
hessian = TRUE,
control = list(fnscale = -1, maxit = 1001))
map_res_02 <- optim(init_guess_02,
my_cv_logpost,
gr = NULL,
hw06_info,
method = "BFGS",
hessian = TRUE,
control = list(fnscale = -1, maxit = 1001))
map_res_01
map_res_02
map_res_02
map_res_01
?optim
my_laplace <- function(start_guess, logpost_func, ...)
{
# code adapted from the `LearnBayes`` function `laplace()`
fit <- optim( start_guess,
logpost_func,
gr = NULL,
...,
method = "BFGS",
hessian =  TRUE,
control = list(fnscale = -1, maxit = 5001))
mode <-  fit$par
post_var_matrix <- -solve(fit$hessian)
p <- length(mode)
# we will discuss what int means in a few weeks...
int <- p/2 * log(2 * pi) + 0.5 * log(det(post_var_matrix)) + logpost_func(mode, ...)
# package all of the results into a list
list(mode = mode ,
var_matrix = post_var_matrix,
log_evidence = int,
converge = ifelse(fit$convergence == 0,
"YES",
"NO"),
iter_counts = as.numeric(fit$counts[1]))
}
laplace_result <-  my_laplace(init_guess_01, my_cv_logpost, hw06_info)
mean1<-laplace_result$mode
mean1
sd1<-sqrt(diag(laplace_result$var_matrix))
sd1
coefficient1<-laplace_result$var_matrix[1, 2] /
(sqrt(laplace_result$var_matrix[1,1]) * sqrt(laplace_result$var_matrix[2,2]))
coefficient1
probability1<-pnorm(mean(hw06_info$xobs),
mean = laplace_result$mode[1],
sd = sqrt(diag(laplace_result$var_matrix))[1])
probability1<-pnorm(mean(hw06_info$xobs),
mean = laplace_result$mode[1],
sd = sqrt(diag(laplace_result$var_matrix))[1])
probability1
generate_post_samples <- function(mvn_info, num_samples)
{
MASS::mvrnorm(n = num_samples,
mu = mvn_info$mode ,
Sigma = mvn_info$var_matrix) %>%
as.data.frame() %>% tibble::as_tibble() %>%
purrr::set_names(c("mu", "varphi")) %>%
mutate(sigma =  exp(varphi) )
}
set.seed(202004)
post_samples <- generate_post_samples(laplace_result, 1e4)
post_samples
posterior_mean<-exp(mean(post_samples$varphi))
posterior_mean
posterior_mean1<-mean(post_samples$sigma)
posterior_mean1
posterior_mean2<-exp(mean(post_samples$varphi))
posterior_mean2
probability2<-mean(post_samples$sigma > 4)
probability2
ggplot(data=post_samples %>% select(mu),
mapping = aes(x = mu)) +
geom_histogram(bins = 55)
ggplot(data=post_samples %>% select(sigma,
mapping = aes(x = sigma )) +
geom_histogram(bins = 55)
ggplot(data=post_samples %>% select(sigma),
mapping = aes(x = sigma )) +
geom_histogram(bins = 55)
map_res_01
map_res_02
coefficient1<-laplace_result$var_matrix[1, 2] /
(sqrt(laplace_result$var_matrix[1,1]) * sqrt(laplace_result$var_matrix[2,2]))
coefficient1
posterior_mean1<-mean(post_samples$sigma)
posterior_mean1
posterior_mean2<-exp(mean(post_samples$varphi))
posterior_mean2
ggplot(data=post_samples %>% select(mu),
mapping = aes(x = mu)) +
geom_histogram(bins = 55)
ggplot(data=post_samples %>% select(sigma),
mapping = aes(x = sigma )) +
geom_histogram(bins = 55)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
hw06_data_path <- "hw06_data.csv"
hw06_df <- readr::read_csv(hw06_data_path, col_names = TRUE)
hw06_df %>% glimpse()
C1<-mean(hw06_df$x)
C2<-sd(hw06_df$x)
C3<-min(hw06_df$x)
C4<-max(hw06_df$x)
C1
C2
C3
C4
hw06_info <- list(
xobs = hw06_df$x,### the meausrements
mu_0 = 11,### mu_0 value
tau_0 = 0.5,### tau_0 value
sigma_rate =0.5 ### rate (lambda) on sigma
)
hw06_info
my_logpost <- function(unknowns, my_info)
{
# unpack the unknowns into separate variables
lik_mu <- unknowns[1]
lik_sigma <- unknowns[2]
# calculate the log-likelihood
log_lik <- sum(dnorm(x = my_info$xobs,
mean = lik_mu,
sd = lik_sigma,
log = TRUE))
# calculate the log-prior on mu
log_prior_mu <- dnorm(x = lik_mu,
mean = my_info$mu_0,
sd = my_info$tau_0,
log = TRUE)
# calculate the log-prior on sigma
log_prior_sigma <-  dexp(x = lik_sigma,
rate = my_info$sigma_rate,
log = TRUE)
# return the (un-normalized) log-posterior
un_log_posterior<-log_lik + log_prior_mu + log_prior_sigma
return (un_log_posterior)
}
my_logpost(c(13, 5), hw06_info)
my_logpost(c(7, 1.5), hw06_info)
expand.grid(x1 = c(1, 2),
x2 = 1:3,
# extra arguments I like to set
KEEP.OUT.ATTRS = FALSE,
stringsAsFactors = FALSE) %>%
# convert to a tibble!
as.data.frame() %>% tibble::as_tibble()
mu_grid_lwr <- hw06_info$mu_0 - 3 * hw06_info$tau_0
mu_grid_upr <- hw06_info$mu_0 + 3 * hw06_info$tau_0
sigma_grid_lwr <- 1
sigma_grid_upr <- qnorm(0.99, hw06_info$mu_0, hw06_info$tau_0)
param_grid <- expand.grid(mu = seq(mu_grid_lwr, mu_grid_upr, length.out = 251),
sigma = seq(sigma_grid_lwr, sigma_grid_upr, length.out = 251),
KEEP.OUT.ATTRS = FALSE, stringsAsFactors = FALSE) %>%
as.data.frame() %>% tibble::as_tibble()
eval_logpost <- function(unknown_1, unknown_2, logpost_func, logpost_info)
{
logpost_func( c(unknown_1, unknown_2), logpost_info )
}
eval_logpost(13, 5, my_logpost, hw06_info)
log_post_result <- purrr::map2_dbl(param_grid$mu, param_grid$sigma,
eval_logpost,
logpost_func = my_logpost,
logpost_info = hw06_info)
param_grid %>%
mutate(log_post = log_post_result,
log_post_2 = log_post - max(log_post)) %>%
ggplot(mapping = aes(x = mu, y = sigma)) +
geom_raster(mapping = aes(fill = log_post_2)) +
stat_contour(mapping = aes(z = log_post_2),
breaks = log(c(0.01/100, 0.01, 0.1, 0.5, 0.9)),
size = 2.2,
color = "black") +
# include the sample average (xbar) and the sample standard deviation (xsd)
geom_point(data = tibble::tibble(xbar =C1, xsd = C2),
mapping = aes(x = xbar, y = xsd),
shape = 22,
size = 4.5, fill = "orange", color = "steelblue") +
scale_fill_viridis_c(guide = FALSE, option = "viridis",
limits = log(c(0.01/100, 1.0))) +
labs(x = expression(mu), y = expression(sigma)) +
theme_bw()
my_cv_logpost <- function(unknowns, my_info)
{
# unpack the unknowns into separate variables
lik_mu <- unknowns[1]
lik_varphi <- unknowns[2]
# back transform to sigma
lik_sigma <- exp(lik_varphi)
# calculate the log-likelihood
log_lik <- sum(dnorm(x = my_info$xobs,
mean = lik_mu,
sd = lik_sigma,
log = TRUE))
# calculate the log-prior on mu
log_prior_mu <- dnorm(x = lik_mu,
mean = my_info$mu_0,
sd = my_info$tau_0,
log = TRUE)
# calculate the log-prior on sigma
log_prior_sigma <- dexp(x = lik_sigma,
rate = my_info$sigma_rate,
log = TRUE)
# calculate the log-derivative adjustment
log_deriv_adjust <-  lik_varphi
# return the (un-normalized) log-posterior
unnormalized_log_p<-log_lik + log_prior_mu + log_prior_sigma + log_deriv_adjust
unnormalized_log_p
}
result1<-my_cv_logpost(c(13, 0), hw06_info)
result1
result2<-my_cv_logpost(c(7, -1), hw06_info)
result2
varphi_grid_lwr <- log(sigma_grid_lwr)
varphi_grid_upr <- log(sigma_grid_upr)
cv_param_grid <- expand.grid(mu =seq(mu_grid_lwr, mu_grid_upr, length.out = 251) ,
varphi =seq(varphi_grid_lwr, varphi_grid_upr, length.out = 251) ,
KEEP.OUT.ATTRS = FALSE, stringsAsFactors = FALSE) %>%
as.data.frame() %>% tibble::as_tibble()
log_post_cv_result <- purrr::map2_dbl(cv_param_grid$mu, cv_param_grid$varphi,
eval_logpost,
logpost_func = my_cv_logpost,
logpost_info = hw06_info)
cv_param_grid %>%
mutate(log_post = log_post_cv_result,
log_post_2 = log_post - max(log_post)) %>%
ggplot(mapping = aes(x = mu, y = varphi)) +
geom_raster(mapping = aes(fill = log_post_2)) +
stat_contour(mapping = aes(z = log_post_2),
breaks = log(c(0.01/100, 0.01, 0.1, 0.5, 0.9)),
size = 2.2,
color = "black") +
# include the sample average (xbar) and the log-sample standard deviation (log_xsd)
geom_point(data = tibble::tibble(xbar =mean(hw06_info$xobs) ,
log_xsd =log(sd(hw06_info$xobs))),
mapping = aes(x = xbar, y = log_xsd),
shape = 22,
size = 4.5, fill = "orange", color = "steelblue") +
scale_fill_viridis_c(guide = FALSE, option = "viridis",
limits = log(c(0.01/100, 1.0))) +
labs(x = expression(mu), y = expression(varphi)) +
theme_bw()
init_guess_01 <- c(10, 0.75)
init_guess_02 <- c(11.75, 1.85)
cv_param_grid %>%
mutate(log_post = log_post_cv_result,
log_post_2 = log_post - max(log_post)) %>%
ggplot(mapping = aes(x = mu, y = varphi)) +
geom_raster(mapping = aes(fill = log_post_2)) +
stat_contour(mapping = aes(z = log_post_2),
breaks = log(c(0.01/100, 0.01, 0.1, 0.5, 0.9)),
size = 2.2,
color = "black") +
# include the initial guess points
geom_point(data = tibble::tibble(attempt = as.character(1:2),
mu = c(init_guess_01[1], init_guess_02[1]),
varphi =c(init_guess_01[2], init_guess_02[2]) ),
mapping = aes(color = attempt),
size = 4.5) +
scale_fill_viridis_c(guide = FALSE, option = "viridis",
limits = log(c(0.01/100, 1.0))) +
labs(x = expression(mu), y = expression(varphi)) +
theme_bw()
map_res_01 <- optim(init_guess_01,
my_cv_logpost,
gr = NULL,
hw06_info,
method = "BFGS",
hessian = TRUE,
control = list(fnscale = -1, maxit = 1001))
map_res_02 <- optim(init_guess_02,
my_cv_logpost,
gr = NULL,
hw06_info,
method = "BFGS",
hessian = TRUE,
control = list(fnscale = -1, maxit = 1001))
map_res_01
map_res_02
my_laplace <- function(start_guess, logpost_func, ...)
{
# code adapted from the `LearnBayes`` function `laplace()`
fit <- optim( start_guess,
logpost_func,
gr = NULL,
...,
method = "BFGS",
hessian =  TRUE,
control = list(fnscale = -1, maxit = 5001))
mode <-  fit$par
post_var_matrix <- -solve(fit$hessian)
p <- length(mode)
# we will discuss what int means in a few weeks...
int <- p/2 * log(2 * pi) + 0.5 * log(det(post_var_matrix)) + logpost_func(mode, ...)
# package all of the results into a list
list(mode = mode ,
var_matrix = post_var_matrix,
log_evidence = int,
converge = ifelse(fit$convergence == 0,
"YES",
"NO"),
iter_counts = as.numeric(fit$counts[1]))
}
laplace_result <-  my_laplace(init_guess_01, my_cv_logpost, hw06_info)
mean1<-laplace_result$mode
mean1
sd1<-sqrt(diag(laplace_result$var_matrix))
sd1
coefficient1<-laplace_result$var_matrix[1, 2] /
(sqrt(laplace_result$var_matrix[1,1]) * sqrt(laplace_result$var_matrix[2,2]))
coefficient1
probability1<-pnorm(mean(hw06_info$xobs),
mean = laplace_result$mode[1],
sd = sqrt(diag(laplace_result$var_matrix))[1])
probability1
generate_post_samples <- function(mvn_info, num_samples)
{
MASS::mvrnorm(n = num_samples,
mu = mvn_info$mode ,
Sigma = mvn_info$var_matrix) %>%
as.data.frame() %>% tibble::as_tibble() %>%
purrr::set_names(c("mu", "varphi")) %>%
mutate(sigma =  exp(varphi) )
}
set.seed(202004)
post_samples <- generate_post_samples(laplace_result, 1e4)
posterior_mean1<-mean(post_samples$sigma)
posterior_mean1
posterior_mean2<-exp(mean(post_samples$varphi))
posterior_mean2
ggplot(data=post_samples %>% select(mu),
mapping = aes(x = mu)) +
geom_histogram(bins = 55)
ggplot(data=post_samples %>% select(sigma),
mapping = aes(x = sigma )) +
geom_histogram(bins = 55)
probability2<-mean(post_samples$sigma > 4)
probability2
